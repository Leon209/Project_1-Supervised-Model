{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Integration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Reading the document<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Excel files with different extensions\n",
    "filename = 'train.csv'\n",
    "file_path = Path(filename)\n",
    "file_extension = file_path.suffix.lower()[1:]\n",
    "\n",
    "if file_extension == 'xlsx':\n",
    "    d = pd.read_excel(file_path, engine='openpyxl')\n",
    "    data = d.copy()\n",
    "elif file_extension == 'xls':\n",
    "    d = pd.read_excel(file_path)\n",
    "    data = d.copy()\n",
    "elif file_extension == 'csv':\n",
    "    d = pd.read_csv(file_path, delimiter=\";\")\n",
    "    data = d.copy()\n",
    "else:\n",
    "    raise Exception(\"File not supported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Access, Exploration and Understanding</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Looking for Null Values<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> By summing the null values for each attribute and then dividing them by the total of values of the same attribute, we will obtain the percentage of null values that each column has. A value different from 0 means that the column has 1 or more missing values, which is not desired. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Checking for duplicate values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We conclude that there are no duplicates in our dataset. Hence, no measures have to be taken into action. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Finding outliers in Year_Birth </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='Year_Birth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Power Transformation for Reward Points <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will now apply a power transformation to make data more Gaussian-like.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='RewardPoints', bins = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "pt.fit(data[\"RewardPoints\"].values.reshape(-1, 1))\n",
    "#print(pt.lambdas_)\n",
    "data['RewardPoints'] = pt.transform(data[\"RewardPoints\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='RewardPoints', bins = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('RewardPointsTransformed.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Use KNN imputer for the missing values in Year_Birth <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object for KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "imputer.fit(data['Year_Birth'].values.reshape(-1, 1))\n",
    "data['Year_Birth'] = imputer.transform(data['Year_Birth'].values.reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As demonstrated above, our data frame no longer has missing values. They have been imputed as the means of k-Nearest Neighbor values. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Transform Year_Birth to age</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now transform the variable Year_Birth to age. We will not use this new variable in our models, but it will be useful in order to better undestand the charactheristics of the population we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "\n",
    "age = today.year - data['Year_Birth']\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgePlot = sns.histplot(data=age, x=age, bins = 15)\n",
    "AgePlot.set_xlabel(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the average age of the people in our dataset is around 40 years old. We will now plot the relation between TypeTravel and Year_Birth to check if there are any outliers in that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"TypeTravel\", y = \"Year_Birth\" , data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are two isolated dots from very old people who are still going on business trips. We will consider these outliers and therefore remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[(data['Year_Birth'] < 1937) & (data['TypeTravel'] == \"business\")].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"TypeTravel\", y = \"Year_Birth\" , data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Transform Name in gender </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"Name\" is not a useful variable for our models, we will transform it to gender. This new variable gives us much better information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = []\n",
    "for i in data[\"Name\"]:\n",
    "    if i[:2] == \"Mr\":\n",
    "        gender.append(1)\n",
    "    else:\n",
    "        gender.append(0)\n",
    "        i\n",
    "data[\"Name\"] = gender\n",
    "data = data.rename(columns = {\"Name\":\"Male\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Change Data types</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the data from longevity to 1 and 0\n",
    "Yes=1 No=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Longevity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Longevity'].replace(to_replace = 'yes',value = 1, inplace = True)\n",
    "data['Longevity'].replace(to_replace = 'y',value = 1, inplace = True)\n",
    "data['Longevity'].replace(to_replace = 'no',value = 0, inplace = True)\n",
    "data['Longevity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Changing the Values of Column \"TypeTravel\"</h4>\n",
    "\n",
    "<p>business = 1 leisure = 0 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TypeTravel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TypeTravel'].replace(to_replace = 'business',value = 1, inplace = True)\n",
    "data['TypeTravel'].replace(to_replace = 'leisure',value = 0, inplace = True)\n",
    "data['TypeTravel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Changing the Values of Column \"Wifi\"</h4>\n",
    "\n",
    "<p>6 were Replaced by 5 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Wifi\", data = data[['Wifi']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scale goes from 0 to 5, it doesn't make sense to have wifi evaluated as a 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Wifi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Wifi'].replace(to_replace = 6,value = 5, inplace = True)\n",
    "data['Wifi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Wifi'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Wifi is evaluated from 0 to 5, like all the other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Changing the Values of Column \"Churn\"</h4>\n",
    "\n",
    "<p>convert \"churn\" and \"nochurn\" to 1 (True) and 0 (False) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'].replace(to_replace = 'churn',value = 1, inplace = True)\n",
    "data['Churn'].replace(to_replace = 'nochurn',value = 0, inplace = True)\n",
    "data['Churn'].value_counts()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change type of Year_birth to int32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After applying the power transformation to Year_Birth, some years became non-integer values. Since this does not make sense, we changed the type of this variable to int in order to round those values. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year_Birth']=data['Year_Birth'].astype(int)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Room Type change</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['RoomType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ordinal Encoding for column RoomType</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RoomType'].replace(to_replace = 'suite',value = 2, inplace = True)\n",
    "data['RoomType'].replace(to_replace = 'double',value = 1, inplace = True)\n",
    "data['RoomType'].replace(to_replace = 'single',value = 0, inplace = True)\n",
    "data['RoomType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pairplots to find out if there is a linear correlation between the variables<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data, kind=\"hist\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data, kind=\"kde\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Pearson Correlation Heatmap</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson correlation\n",
    "cor_pearson= data.corr(method ='pearson')\n",
    "#Heatmap function defined\n",
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(data = cor, annot = True, cmap = plt.cm.Reds, fmt='.1')\n",
    "    plt.show()\n",
    "#print correlation\n",
    "cor_heatmap(cor_pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Kendall Correlation Heatmap</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Kendall correlation\n",
    "cor_kendall= data.corr(method ='kendall')\n",
    "#Heatmap function defined\n",
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(data = cor, annot = True, cmap = plt.cm.Reds, fmt='.1')\n",
    "    plt.show()\n",
    "#print correlation\n",
    "cor_heatmap(cor_kendall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature Selection</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With the correlation map we were able see which features had a greater impact on the outcome (Churn) and which ones didn't. It also allowed us to see that there are some features that have a high correlation between them. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Cust_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Since variables that are measured at different scales do not contribute equally to the model fitting and model learned function and might end up creating a bias, we will deal with this potential problem by applying a MinMax Normalization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop('Churn', axis = 1)\n",
    "y_train = data['Churn']\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "minmax_train = scaler.transform(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(minmax_train, columns = X_train.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova = SelectKBest(f_classif, k=15)\n",
    "X_anova = anova.fit_transform(X_train, y_train)\n",
    "selected_features = pd.Series(anova.get_support(), index = X_train.columns)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>VALIDATION</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying all these steps to the train dataset, the same must be done to the validation and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data preparation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the validation data\n",
    "filename1 = 'validation.csv'\n",
    "file_path1 = Path(filename1)\n",
    "v = pd.read_csv(file_path1, delimiter=\";\")\n",
    "validate = v.copy()\n",
    "#Longevity\n",
    "validate['Longevity'].replace(to_replace = 'yes',value = 1, inplace = True)\n",
    "validate['Longevity'].replace(to_replace = 'y',value = 1, inplace = True)\n",
    "validate['Longevity'].replace(to_replace = 'no',value = 0, inplace = True)\n",
    "#TypeTravel\n",
    "validate['TypeTravel'].replace(to_replace = 'business',value = 1, inplace = True)\n",
    "validate['TypeTravel'].replace(to_replace = 'leisure',value = 0, inplace = True)\n",
    "#Churn\n",
    "validate['Churn'].replace(to_replace = 'churn',value = 1, inplace = True)\n",
    "validate['Churn'].replace(to_replace = 'nochurn',value = 0, inplace = True)\n",
    "#RoomType\n",
    "validate['RoomType'].replace(to_replace = 'suite',value = 2, inplace = True)\n",
    "validate['RoomType'].replace(to_replace = 'double',value = 1, inplace = True)\n",
    "validate['RoomType'].replace(to_replace = 'single',value = 0, inplace = True)\n",
    "\n",
    "#PowerTransformation for RewardPoints\n",
    "validate['RewardPoints'] = pt.transform(validate[\"RewardPoints\"].values.reshape(-1, 1))\n",
    "\n",
    "#name to gender conversion\n",
    "gender = []\n",
    "for i in validate[\"Name\"]:\n",
    "    if i[:2] == \"Mr\":\n",
    "        gender.append(1)\n",
    "    else:\n",
    "        gender.append(0)\n",
    "        i\n",
    "validate[\"Name\"] = gender\n",
    "validate = validate.rename(columns = {\"Name\":\"Male\"})\n",
    "\n",
    "#column removal \n",
    "validate.drop(columns=['Cust_ID'], inplace=True)\n",
    "\n",
    "validate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Checking for missing values</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate.drop('Churn', axis = 1)\n",
    "y_validate = validate['Churn']\n",
    "\n",
    "minmax_validate = scaler.transform(X_validate)\n",
    "\n",
    "X_validate = pd.DataFrame(minmax_validate, columns = X_validate.columns)\n",
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TEST</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data Preparation<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the test data\n",
    "filename2 = 'test.csv'\n",
    "file_path2 = Path(filename2)\n",
    "t = pd.read_csv(file_path2, delimiter=\";\")\n",
    "test = t.copy()\n",
    "#Longevity\n",
    "test['Longevity'].replace(to_replace = 'yes',value = 1, inplace = True)\n",
    "test['Longevity'].replace(to_replace = 'y',value = 1, inplace = True)\n",
    "test['Longevity'].replace(to_replace = 'no',value = 0, inplace = True)\n",
    "#TypeTravel\n",
    "test['TypeTravel'].replace(to_replace = 'business',value = 1, inplace = True)\n",
    "test['TypeTravel'].replace(to_replace = 'leisure',value = 0, inplace = True)\n",
    "#RoomType\n",
    "test['RoomType'].replace(to_replace = 'suite',value = 2, inplace = True)\n",
    "test['RoomType'].replace(to_replace = 'double',value = 1, inplace = True)\n",
    "test['RoomType'].replace(to_replace = 'single',value = 0, inplace = True)\n",
    "\n",
    "#PowerTransformation for RewardPoints\n",
    "test['RewardPoints'] = pt.transform(test[\"RewardPoints\"].values.reshape(-1, 1))\n",
    "\n",
    "#name to gender conversion\n",
    "gender = []\n",
    "for i in test[\"Name\"]:\n",
    "    if i[:2] == \"Mr\":\n",
    "        gender.append(1)\n",
    "    else:\n",
    "        gender.append(0)\n",
    "        i\n",
    "test[\"Name\"] = gender\n",
    "test = test.rename(columns = {\"Name\":\"Male\"})\n",
    "\n",
    "#column removal \n",
    "customers = test['Cust_ID']\n",
    "test.drop(columns=['Cust_ID'], inplace=True)\n",
    "\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Scaling<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test\n",
    "\n",
    "minmax_test = scaler.transform(X_test)\n",
    "\n",
    "X_test = pd.DataFrame(minmax_test, columns = X_test.columns)\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modeling and Assessment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Model Evaluation Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model):\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    timer = []\n",
    "    f1_score_val = []\n",
    "    f1_score_train = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        begin = time.perf_counter() # start counting time\n",
    "        model.fit(X_train, y_train) # fit your model to your training data\n",
    "        end = time.perf_counter() # stop counting time\n",
    "        \n",
    "        value_train = model.score(X_train, y_train) # mean accuracy for train\n",
    "        value_val = model.score(X_validate, y_validate) # mean accuracy for validation\n",
    "        score_train.append(value_train) # append the mean accuracy in train to your list score_train\n",
    "        score_val.append(value_val) # append the mean accuracy in validation to your list score_val\n",
    "        timer.append(end-begin) # append the time to your list timer\n",
    "        f1_score_val.append(f1_score(model.predict(X_validate), y_validate))\n",
    "        f1_score_train.append(f1_score(model.predict(X_train), y_train))\n",
    "        \n",
    "    \n",
    "    avg_time = round(np.mean(timer),3) # check the mean value of training time for your 10 models \n",
    "    avg_train = round(np.mean(score_train),3) # check the mean accuracy in train for your 10 models\n",
    "    avg_val = round(np.mean(score_val),3) # check the mean accuracy in validation for your 10 models\n",
    "    std_time = round(np.std(timer),2) # check the standard deviation of training time for your 10 models\n",
    "    std_train = round(np.std(score_train),2) # check the standard deviation of the mean accuracy in train for your 10 models\n",
    "    std_val = round(np.std(score_val),2) # check the standard deviation of the mean accuracy in validation for your 10 models\n",
    "    avg_f1_val = round(np.mean(f1_score_val),3)\n",
    "    avg_f1_train = round(np.mean(f1_score_train),3)\n",
    "    \n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_train) + '+/-' + str(std_train),\\\n",
    "str(avg_val) + '+/-' + str(std_val), str(avg_f1_train), str(avg_f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, models):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for model in models:\n",
    "        # obtain the results provided by avg_score\n",
    "        time, avg_train, avg_val, avg_f1_train, avg_f1_val = avg_score(model)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = time, avg_train, avg_val, avg_f1_train, avg_f1_val\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>KNN Classifier</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['Raw'])\n",
    "show_results(df, [modelKNN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decision Trees</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDT = DecisionTreeClassifier(splitter = 'random',criterion = 'entropy',random_state=5,max_depth = 10, min_samples_split=4,min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['Raw'])\n",
    "show_results(df, [modelDT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The defined three has a depth of ' + str(modelDT.get_depth()) + ', ' + str(modelDT.tree_.node_count) + \n",
    "      ' nodes and a total of ' + str(modelDT.get_n_leaves()) + ' leaves.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDT.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X_train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(modelDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_reg = LogisticRegression(class_weight='balanced')\n",
    "model_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = model_log_reg.predict(X_train)\n",
    "labels_val = model_log_reg.predict(X_validate)\n",
    "\n",
    "print('----------------------- TRAIN -----------------------')\n",
    "print(classification_report(y_train, labels_train))\n",
    "print('--------------------- VALIDATION ---------------------')\n",
    "print(classification_report(y_validate, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Neural Networks</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLP = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['Raw'])\n",
    "show_results(df, [modelMLP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = MLPClassifier(hidden_layer_sizes=(5))\n",
    "model_medium = MLPClassifier(hidden_layer_sizes=(10,10))\n",
    "model_complex = MLPClassifier(hidden_layer_sizes=(20, 20))\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['Simple','Medium','Complex'])\n",
    "show_results(df, [model_simple, model_medium, model_complex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = MLPClassifier(activation='logistic')\n",
    "model_tanh = MLPClassifier(activation='tanh')\n",
    "model_relu = MLPClassifier(activation='relu')\n",
    "model_identity = MLPClassifier(activation='identity')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['logistic','tanh', 'relu', 'identity'])\n",
    "show_results(df, [model_logistic, model_tanh, model_relu, model_identity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = MLPClassifier(solver = 'sgd')\n",
    "model_adam = MLPClassifier(solver = 'adam')\n",
    "model_lbfgs = MLPClassifier(solver = 'lbfgs')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['sgd','adam', 'lbfgs'])\n",
    "show_results(df, [model_sgd, model_adam, model_lbfgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constant = MLPClassifier(solver = 'sgd', learning_rate = 'constant')\n",
    "model_invscaling = MLPClassifier(solver = 'sgd', learning_rate = 'invscaling')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'f1 Train', 'f1 Validation'], index = ['constant','invscaling'])\n",
    "show_results(df, [model_constant, model_invscaling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = { #we still need to adjust these parameters\n",
    "    'hidden_layer_sizes': [(40,40), (40, 40, 40)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate_init': [0.00001, 0.001, 0.1],\n",
    "    'learning_rate': ['constant']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(modelMLP, parameter_space)\n",
    "clf.fit(X_train, y_train)\n",
    "final_model = clf.best_estimator_\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['final_model'])\n",
    "show_results(df, [final_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Linear SVC Model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_classification(n_features=18, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation','F1 Train','F1 Validation'], index = ['Linear SVC'])\n",
    "show_results(df, [clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gaussian Naive Bayes Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gaussian = GaussianNB()\n",
    "model_gaussian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = model_gaussian.predict(X_train)\n",
    "labels_val = model_gaussian.predict(X_validate)\n",
    "\n",
    "print('----------------------- TRAIN -----------------------')\n",
    "print(classification_report(y_train, labels_train))\n",
    "print('--------------------- VALIDATION ---------------------')\n",
    "print(classification_report(y_validate, labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_randomForest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gini = RandomForestClassifier(criterion='gini')\n",
    "model_entropy= RandomForestClassifier(criterion='entropy')\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'f1 Train', 'f1 Validation'], index = ['gini','entropy'])\n",
    "show_results(df, [model_gini, model_entropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small_maxdepth = RandomForestClassifier(max_depth=5)\n",
    "model_medium_maxdepth = RandomForestClassifier(max_depth=10)\n",
    "model_big_maxdepth = RandomForestClassifier(max_depth=15)\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'f1 Train', 'f1 Validation'], index = ['small','medium', 'big'])\n",
    "show_results(df, [model_small_maxdepth, model_medium_maxdepth, model_big_maxdepth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small_min_samples_leaf = RandomForestClassifier(min_samples_leaf=3)\n",
    "model_medium_min_samples_leaf = RandomForestClassifier(min_samples_leaf=5)\n",
    "model_big_min_samples_leaf = RandomForestClassifier(min_samples_leaf=8)\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'f1 Train', 'f1 Validation'], index = ['small','medium', 'big'])\n",
    "show_results(df, [model_small_min_samples_leaf, model_medium_min_samples_leaf, model_big_min_samples_leaf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space_random_forest = {\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [5, 10], \n",
    "    'min_samples_leaf': [3,4, 5],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model_randomForest, parameter_space_random_forest)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_\n",
    "final_model_forest = clf.best_estimator_\n",
    "\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'f1 Train', 'f1 Validation'], index = ['final_model_forest'])\n",
    "show_results(df, [final_model_forest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_forest.fit(X_train, y_train)\n",
    "print(final_model_forest.predict(X_validate))\n",
    "final_model_forest.score(X_train, y_train)\n",
    "final_model_forest.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deployment and Monitoring</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = model_log_reg.predict(X_test)\n",
    "answer = pd.DataFrame([customers, deploy]).T\n",
    "answer = answer.rename(columns={\"Cust_ID\": \"Customer ID\", \"Unnamed 0\": \"Churn\"})\n",
    "answer.to_excel('202122 Spring Lic Group06 Answer With Log Reg .xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
